{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drowsy_face_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+vyUGvoFqtddbElVNh+zM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oussamayousre/DLL/blob/main/VideoDataGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X8CCOVEQZNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e7398c-ab49-4ac7-bc8d-875d5f93cab8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh1AMeGF-9Qi",
        "outputId": "395588d4-3297-4739-c3d4-51555206132a"
      },
      "source": [
        "!git clone https://github.com/metal3d/keras-video-generators.git  \n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-video-generators'...\n",
            "remote: Enumerating objects: 608, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 608 (delta 43), reused 76 (delta 35), pack-reused 514\u001b[K\n",
            "Receiving objects: 100% (608/608), 7.76 MiB | 27.86 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyAeektVCb0Y",
        "outputId": "782c3a94-3f28-4063-d28c-79211c26c969"
      },
      "source": [
        "!pip install keras-video-generators\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-video-generators\n",
            "  Downloading keras-video-generators-1.0.14.tar.gz (11 kB)\n",
            "Requirement already satisfied: keras>=2 in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2->keras-video-generators) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->keras-video-generators) (1.15.0)\n",
            "Building wheels for collected packages: keras-video-generators\n",
            "  Building wheel for keras-video-generators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-video-generators: filename=keras_video_generators-1.0.14-py3-none-any.whl size=12882 sha256=e03ed941dc0307e5495f09d761347e95350d9810c123a11a01df2c36c8582c02\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/22/94/eda4e8caf00c0ffd3030fecbf2e0334b8a7f038f4451e20b00\n",
            "Successfully built keras-video-generators\n",
            "Installing collected packages: keras-video-generators\n",
            "Successfully installed keras-video-generators-1.0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtTJM8lQm5VP"
      },
      "source": [
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras import datasets ,layers,models\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from scipy.spatial import distance as dist\n",
        "from imutils.video import FileVideoStream\n",
        "from scipy.signal import argrelextrema\n",
        "from imutils.video import VideoStream\n",
        "#from keras_video import VideoFrameGenerator\n",
        "from imutils import face_utils\n",
        "import numpy as np\n",
        "import argparse\n",
        "#import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "# calculate a face embedding for each face in the dataset using facenet\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        "\n",
        "# calculate a face embedding for each face in the dataset using facenet\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esjgoJZ01Kkx"
      },
      "source": [
        "\"\"\"arr = os.listdir(\"/content/gdrive/MyDrive/DataBase\")\n",
        "#label_train  = np.array([])\n",
        "#Frame_train = np.array([])\n",
        "i = 0\n",
        "for path_1 in arr :\n",
        "\n",
        "  \n",
        "  \n",
        "  #print(arr)\n",
        "  #verify if the path is a directory or just a hidden file\n",
        "  full_path_1 = f\"/content/gdrive/MyDrive/DataBase/{path_1}\" \n",
        "  isDirectory = os.path.isdir(full_path_1)\n",
        "  if isDirectory : \n",
        "    arr_1 = os.listdir(full_path_1)\n",
        "    \n",
        "    for path_2 in arr_1 : \n",
        "      full_path_2 = f\"/content/gdrive/MyDrive/DataBase/{path_1}/{path_2}\" \n",
        "      arr_2 = os.listdir(full_path_2)\n",
        "      \n",
        "      for path_3 in arr_2 :\n",
        "        i += 1 \n",
        "        label_train  = []\n",
        "        Frame_train = [] \n",
        "        #).reshape(0,1).astype(np.int64)\n",
        "        label = int(os.path.splitext(path_3)[0])\n",
        "        full_path_2 = f\"/content/gdrive/MyDrive/DataBase/{path_1}/{path_2}/{path_3}\"\n",
        "        \n",
        "        vs = cv2.VideoCapture(full_path_2)\n",
        "        while True :\n",
        "          ret, image = vs.read()\n",
        "          if ret == False : \n",
        "            break\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "          image = cv2.resize(image, (224, 224))\n",
        "          #image = image.img_to_array(image)\n",
        "          label_train.append(label)\n",
        "          Frame_train.append(image)\n",
        "        #train classes \n",
        "        np.save(f'/content/gdrive/MyDrive/variables/X_dataset{i}.npy', Frame_train) # save\n",
        "        #train labels\n",
        "        np.save(f'/content/gdrive/MyDrive/variables/y_dataset{i}.npy', label_train) # save\n",
        "        vs.release()\n",
        "        cv2.destroyAllWindows()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_zVePI3a_d"
      },
      "source": [
        "#next step is to collect all the videos in one folder and take the first character of their name which is the label \n",
        "import numpy as np\n",
        "import keras\n",
        "#path to video's folder\n",
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "#\n",
        "train_ID = os.listdir(path)[1:]\n",
        "class VideoFrameGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,train_ID, batch_size=1, dim=(56,56), shuffle=True ):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.train_ID = train_ID   \n",
        "        self.shuffle = shuffle\n",
        "        self.dim = dim\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.train_ID) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.train_ID[k] for k in indexes]\n",
        "        #list_IDs_temp = [20]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        X =  np.array([X])[0]\n",
        "        y =  np.array([y])\n",
        "        y = y.reshape(y.shape[1],1)\n",
        "        randomize = np.arange(y.shape[0])\n",
        "        np.random.shuffle(randomize)\n",
        "        X = X[randomize]\n",
        "        y = y[randomize]\n",
        "        return X , y \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.train_ID))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}')\n",
        "        label_train  = []\n",
        "        Frame_train = [] \n",
        "        # Generate data\n",
        "        for path_3 in arr_1 : \n",
        "          #).reshape(0,1).astype(np.int64)\n",
        "          label = int(os.path.splitext(path_3)[0])\n",
        "          full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}/{path_3}\"\n",
        "          vs = cv2.VideoCapture(full_path_2)\n",
        "          nb_frame = 0\n",
        "          while True :\n",
        "            ret, image = vs.read()\n",
        "            if ret == False  or nb_frame == 1000  : \n",
        "              break\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, self.dim)\n",
        "            #image = image.img_to_array(image)\n",
        "            label_train.append(label)\n",
        "            Frame_train.append(image)\n",
        "            nb_frame += 1\n",
        "          vs.release()\n",
        "          cv2.destroyAllWindows()\n",
        "        return Frame_train, label_train\n",
        "     \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WQjd3_uDlxR"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "train_ID = os.listdir(path)[1:]\n",
        "\n",
        "# Parameters\n",
        "params = {'dim': (56,56),\n",
        "          'batch_size': 1,\n",
        "          'shuffle': True}\n",
        "training_generator = VideoFrameGenerator(train_ID, **params)\n",
        "validation_generator = VideoFrameGenerator([19], **params)\n",
        " "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AauwousQJoKk"
      },
      "source": [
        "\"\"\"model = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Conv2D(32, (3,3) , activation = 'relu' ,padding='same', input_shape = (56,56,3), kernel_regularizer=l2(0.01) ),\n",
        "              tf.keras.layers.MaxPool2D(pool_size=(2, 2) ),\n",
        "              #\n",
        "              tf.keras.layers.Conv2D(32 , (3,3) ,padding='same', activation = 'relu',kernel_regularizer=l2(0.01)),\n",
        "              tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
        "              #\n",
        "              tf.keras.layers.Conv2D(64 , (3,3) , activation = 'relu', padding='same', kernel_regularizer=l2(0.01)),\n",
        "              #tf.keras.layers.Dropout(0.2),\n",
        "              tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
        "              #\n",
        "            \n",
        "              #\n",
        "              #  tf.keras.layers.Conv2D(256 , (3,3) , activation = 'relu'),\n",
        "              #  tf.keras.layers.Dropout(0.2),\n",
        "              # tf.keras.layers.BatchNormalization() ,\n",
        "              # tf.keras.layers.MaxPool2D(2,2),\n",
        "              #\n",
        "              tf.keras.layers.Flatten(),\n",
        "              ##\n",
        "              tf.keras.layers.Dense(64 , activation = 'relu', kernel_regularizer=l2(0.01)),\n",
        "              #tf.keras.layers.Dropout(0.2),\n",
        "              tf.keras.layers.Dense(11,activation = 'softmax' ) ]\n",
        "               \n",
        "    )\n",
        "model.summary()\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf0F1fymKKiP"
      },
      "source": [
        "\"\"\"opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer = opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(training_generator, validation_data=validation_generator, epochs = 10 )\n",
        "#change 56 to 224 first thing to do \n",
        "history\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yge7Gpt9cnxf"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "train_ID = os.listdir(path)[1:]\n",
        "class VideoFrameGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,train_ID, batch_size=1, dim=(50,50), shuffle=True ):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.train_ID = train_ID   \n",
        "        self.shuffle = shuffle\n",
        "        self.dim = dim\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.train_ID) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.train_ID[k] for k in indexes]\n",
        "        #list_IDs_temp = [20]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        randomize = np.arange(len(x))\n",
        "        np.random.shuffle(randomize)\n",
        "        X = X[randomize]\n",
        "        y = y[randomize]\n",
        "        return np.array([X]), np.array([y])\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.train_ID))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}')\n",
        "        # Generate data\n",
        "        for path_3 in arr_1 : \n",
        "          label_train  = []\n",
        "          Frame_train = [] \n",
        "          #).reshape(0,1).astype(np.int64)\n",
        "          label = int(os.path.splitext(path_3)[0])\n",
        "          full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}/{path_3}\"\n",
        "\n",
        "          vs = cv2.VideoCapture(full_path_2)\n",
        "          while True :\n",
        "            ret, image = vs.read()\n",
        "            if ret == False : \n",
        "              break\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, self.dim)\n",
        "            #image = image.img_to_array(image)\n",
        "            label_train.append(label)\n",
        "            Frame_train.append(image)\n",
        "          vs.release()\n",
        "          cv2.destroyAllWindows()\n",
        "        return Frame_train,label_train\n",
        "     \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LLvQ_K7g_Wi"
      },
      "source": [
        "x ,y = training_generator.__getitem__(0)\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7QeXOoFgdu2",
        "outputId": "7e711e59-3c88-4a12-a721-dae4e5e35938"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_eXmU4LjcAg"
      },
      "source": [
        "##############################################################\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioQMCmWcgjVw",
        "outputId": "10b1ee58-339c-47c0-f31a-ecde34d379dc"
      },
      "source": [
        "# confirm mtcnn was installed correctly\n",
        "import mtcnn\n",
        "# print version\n",
        "print(mtcnn.__version__)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRXbkGEKgmYW",
        "outputId": "bc24d3f6-5868-44a6-8251-a95df63f64b1"
      },
      "source": [
        "! pip install gdown"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfP21302hxp5",
        "outputId": "3f3c4103-c421-4603-9e30-c194db2893b2"
      },
      "source": [
        "import gdown\n",
        "!gdown --id 1PZ_6Zsy1Vb0s0JmjEmVd8FS99zoMCiN1"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PZ_6Zsy1Vb0s0JmjEmVd8FS99zoMCiN1\n",
            "To: /content/facenet_keras.h5\n",
            "92.4MB [00:00, 150MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrNBLordieH1"
      },
      "source": [
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(pixels, required_size=(160, 160)): \n",
        "    detector = MTCNN() \n",
        "    # create the detector, using default weights   \n",
        "    # detect faces in the image\n",
        "    results = detector.detect_faces(pixels)\n",
        "    if len(results) == 0 : \n",
        "      return np.array([]).reshape(0, 160, 160, 3)\n",
        "    # extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "    # bug fix\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        "    return face_array\n",
        " \n",
        "# load the photo and extract the face"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNp6tcQ-h0Oz",
        "outputId": "bb33e509-462c-4928-e971-74ca026f581b"
      },
      "source": [
        "\n",
        "model_facenet = tf.keras.models.load_model('/content/facenet_keras.h5')\n",
        "print('Loaded Model')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Loaded Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQkZhjh7h2kh",
        "outputId": "c4d9a2b9-7d05-4869-8cf4-d046d56f11bf"
      },
      "source": [
        "print(model_facenet.inputs)\n",
        "print(model_facenet.outputs)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<KerasTensor: shape=(None, 160, 160, 3) dtype=float32 (created by layer 'input_1')>]\n",
            "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'Bottleneck_BatchNorm')>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI62bCi0iShx"
      },
      "source": [
        "# get the face embedding for one face\n",
        "def get_embedding(model_facenet , face_pixels):\n",
        "    # scale pixel values\n",
        "    face_pixels = face_pixels.astype('float32')\n",
        "    # standardize pixel values across channels (global)\n",
        "    mean, std = face_pixels.mean(), face_pixels.std()\n",
        "    face_pixels = (face_pixels - mean) / std\n",
        "    # transform face into one sample\n",
        "    samples = expand_dims(face_pixels, axis=0)\n",
        "    # make prediction to get embedding\n",
        "    yhat = model_facenet.predict(samples)\n",
        "    return yhat[0]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwxOfN1SkHDK"
      },
      "source": [
        "### test code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lieRQsP7iWmv"
      },
      "source": [
        "arr_1 = os.listdir('/content/gdrive/MyDrive/variables/Fold3_part1/25')\n",
        "# Generate data\n",
        "for path_3 in arr_1 : \n",
        "  label_train  = np.array([])\n",
        "  Frame_train = np.array([]).reshape(0,128)\n",
        "  #).reshape(0,1).astype(np.int64)\n",
        "  label = int(os.path.splitext(path_3)[0])\n",
        "  full_path_2 = f\"/content/gdrive/MyDrive/variables/Fold3_part1/25/{path_3}\"\n",
        "  #print(label)\n",
        "  vs = cv2.VideoCapture(full_path_2)\n",
        "  nb_frame = 0\n",
        "  \n",
        "  while True :\n",
        "    detector = MTCNN()\n",
        "    ret, image = vs.read()\n",
        "    if ret == False or nb_frame == 3 : \n",
        "\n",
        "      break\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    #print(image.shape)\n",
        "    image = extract_face(image,required_size=(160, 160))\n",
        "    print(image.shape)\n",
        "    if len(image) == 0  :                \n",
        "        #face_features = np.array([]).reshape(0,128)\n",
        "        nb_frame += 1\n",
        "    else : \n",
        "        face_features = get_embedding(model_facenet , image)             \n",
        "        face_features = np.array(face_features) \n",
        "        face_features = face_features.reshape(1,128)\n",
        "        label_train = np.append(label_train , label)\n",
        "        Frame_train = np.append(Frame_train , face_features ,axis=0)\n",
        "        nb_frame += 1\n",
        "    #image = image.img_to_array(image)\n",
        "    #label_train = np.append(label_train , label)\n",
        "    #Frame_train = np.append(Frame_train , face_features ,axis=0)\n",
        "     \n",
        "  vs.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVi5BRfTI11H"
      },
      "source": [
        "#next step is to collect all the videos in one folder and take the first character of their name which is the label \n",
        "#path to videos folder\n",
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "#list of subfolders ID, os.listdir(path)[0] is for the validation data\n",
        "train_ID = os.listdir(path)[1:]\n",
        "class VideoFrameGenerator(Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self,train_ID , model_facenet ,detector = MTCNN(), batch_size=1, dim=(56,56), shuffle=True):\n",
        "        'Initialization'\n",
        "        self.batch_size = batch_size\n",
        "        self.train_ID = train_ID   \n",
        "        self.shuffle = shuffle\n",
        "        self.model_facenet = model_facenet\n",
        "        self.dim = dim\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.train_ID) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.train_ID[k] for k in indexes]\n",
        "        #list_IDs_temp = [20]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "        #X =  np.array([X])[0]\n",
        "        #y =  np.array([y])\n",
        "        #y = y.reshape(y.shape[1],1)\n",
        "        print(X.shape)\n",
        "        print(y.shape)\n",
        "        return X , y \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.train_ID))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        #X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        #y = np.empty((self.batch_size), dtype=int)\n",
        "        arr_1 = os.listdir(f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}')\n",
        "        # Generate data\n",
        "        label_train  = np.array([]).reshape(0,1)\n",
        "        Frame_train = np.array([]).reshape(0,128)\n",
        "        for path_3 in arr_1 :\n",
        "            #labeling the data using the title of videos \n",
        "            label = int(os.path.splitext(path_3)[0])\n",
        "            full_path_2 = f'/content/gdrive/MyDrive/variables/Fold2_part2/{list_IDs_temp[0]}/{path_3}'\n",
        "            # Opens the Video file\n",
        "            \n",
        "            vs = cv2.VideoCapture(full_path_2)\n",
        "            nb_frame = 1        \n",
        "            while True :    \n",
        "                ret, image = vs.read()\n",
        "                if ret == False or nb_frame == 3 : \n",
        "                    break\n",
        "                \n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                #print(image.shape)\n",
        "                image = extract_face(image,required_size=(160, 160))\n",
        "                #image = cv2.resize(image, (160,160))\n",
        "                if len(image) == 0 :                \n",
        "                    #face_features = np.array([]).reshape(0,128)\n",
        "                    nb_frame += 1 \n",
        "                else : \n",
        "                    face_features = get_embedding(self.model_facenet , image)             \n",
        "                    face_features = np.array(face_features) \n",
        "                    face_features = face_features.reshape(1,128)\n",
        "                    label_train = np.append(label_train , label)\n",
        "                    Frame_train = np.append(Frame_train , face_features ,axis=0)\n",
        "                    nb_frame += 1 \n",
        "                #image = image.img_to_array(image)\n",
        "                #label_train = np.append(label_train , label)\n",
        "                #Frame_train = np.append(Frame_train , face_features ,axis=0)\n",
        "                \n",
        "            vs.release()\n",
        "            cv2.destroyAllWindows()\n",
        "        return Frame_train, label_train.reshape(label_train.shape[0]).astype(int)\n",
        "     \n"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfkOqeWHRlnj"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/variables/Fold2_part2'\n",
        "train_ID = os.listdir(path)[1:]\n",
        "\n",
        "# Parameters\n",
        "params = {'model_facenet' : model_facenet , \n",
        "          'batch_size': 1,\n",
        "          'shuffle': True}\n",
        "training_generator = VideoFrameGenerator(train_ID, **params)\n",
        "validation_generator = VideoFrameGenerator([os.listdir(path)[0]], **params)\n",
        " "
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8waLLO04aaf"
      },
      "source": [
        "x ,y = training_generator.__getitem__(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SsB8BTL5OQL"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DaFjMdyenBk"
      },
      "source": [
        "\n",
        "model = models.Sequential([\n",
        "          layers.Dense(256,activation='relu'),\n",
        "          layers.Dense(128,activation='relu'),\n",
        "          layers.Dense(64,activation='relu'),\n",
        "          layers.Dense(32,activation='relu'),\n",
        "          layers.Dense(16,activation='relu'),\n",
        "          layers.Dense(11,activation='softmax'),\n",
        "\n",
        "])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "history = model.fit(training_generator , validation_data= validation_generator, epochs = 2 )\n",
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebf-csAte2CS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}